Code can be found at industrial_training repository in gh_pages folder. Use kinetic branch.

*__Just want to make sure that this will eventually be true, because of course it is not currently__

# Building a Python Service Node

In this exercise, we will fill in the appropriate pieces of code to build a perception pipeline. The end goal will be to broadcast a transform with the pose information of the object of interest.

*__I don't think this end goal matches the actual end goal__


# Prepare New Workspace:

We will create a new catkin workspace, since this exercise does not overlap with the previous PlanNScan exercises.

1. Disable automatic sourcing of your previous catkin workspace:
    1. <code>gedit ~/.bashrc</code>

    2. comment out <code>#</code> the last line, sourcing your <code>~/catkin_ws/devel/setup.bash</code>


        source /opt/ros/kinetic/setup.bash
        
    *__I don't understand why this is necessary. "source /opt/ros/kinetic/setup.bash" is in your .bashrc, meaning you don't need to run it. There is also no reason to disable the sourcing of the other tutorial workspace. If they have that already, it will do no harm, and if they don't, again, it doesn't make a difference.__


2. Copy the template workspace layout and files:

        cp -r ~/industrial_training/exercises/perception_ws ~
        cd ~/perception_ws/

    *__This may not be the correct directions. That is the skeleton workspace for the earlier perception pipeline tutorial. If this tutorial is replacing that one, that works, but unless it is, it should be its own directory.__

3. Initialize and Build this new workspace

        catkin init
        catkin build


4. Source the workspace

        source ~/perception_ws/devel/setup.bash

5. Download the PointCloud file and place the file in your home directory (~).

*__Where can I download the PointCloud file?__

6. Import the new workspace into your QTCreator IDE: In QTCreator: File -> New Project -> Import -> Import ROS Workspace -> ~/perception_ws


# Intro (Review Existing Code)

Most of the infrastructure for a ros node has already been completed for you; the focus of this exercise is the perception algorithms/pipleline. The <code>CMakelists.txt</code> and <code>package.xml</code> are complete and a source file has been provided. You could build the source as is, but you would get errors. At this time we will explore the source code that has been provided - browse the provided <code>perception_node.cpp</code> file. This tutorial is a rehash of training <a href="Exercise 5.1 Building a Perception Pipeline" target="http://ros-industrial.github.io/industrial_training/_source/session5/Building-a-Perception-Pipeline.html">Exercise 5.1 Building a Perception Pipeline</a> and as such the C++ code has already been set up.  If something does not make sense, revisit that exercise.  Open up the preception_node.cpp file and look over the filtering functions.

# Create a Python node

*__May want to rename this section. This is the creation of a package, not a node__

Now that we have converted several filters to C++ functions, we are ready to call it from a Python node.  If you have not done so already, install PyCharm, community edition.  This IDE has the necessary parser for editing, without it, you will not be able to review any syntax issues in Qt.

1.	In the terminal, change the directory to your src folder. Create a new package inside your perception_ws:


        cd ~/perception_ws/src/
        catkin_create_pkg filter_call rospy roscpp perception_msgs

    *__You actually do not need these dependencies at all for the node to work. We use no C++ and perception_msgs just breaks the build. rospy is only really needed if we plan on having this package available as anything other than a standalone node__

2.	Check that your package was created:

        ls

     We will not be using ‘perception_msgs’ as we will not be creating custom messages in this course.  It is included for further student knowledge. If you wish for a more in depth explanation including how to implement customer messages, here is a good <a href="MIT resource" target="http://duckietown.mit.edu/media/pdfs/1rpRisFoCYUm0XT78j-nAYidlh-cDtLCdEbIaBCnx9ew.pdf">MIT resource</a> on the steps taken.
     
     *__Still may want to look into what is this for and whether or not things break__


3.	Open *CMakeLists.txt*. You can open the file in Pycharm or Qt (or you can use nano, emacs, vim, or sublime). Uncomment line 23, and save.

        catkin_python_setup()

    *__Whether this is needed or not is questionable. We are building a standalone node that is not being planned on being used in other modules. So this as well as any dependencies in CMakeLists.txt and package.xml, setup.py, and \__init\__.py are all possibly not needed__

# <big>Creating setup.py</big>

The <code>setup.py</code> file makes your python module available to the entire workspace and subsequent packages.  By default, this isn’t created by the <code>catkin_create_pkg</code> command.

1.	In your terminal type

        nano filter_call/setup.py

2.	Copy and paste the following to the <code>setup.py</code> file (to paste into a terminal, Ctrl+Shift+V)

        ## ! DO NOT MANUALLY INVOKE THIS setup.py, USE CATKIN INSTEAD
        from distutils.core import setup
        from catkin_pkg.python_setup import generate_distutils_setup
        # fetch values from package.xml
        setup_args = generate_distutils_setup(
        packages=[''],
        package_dir={'': 'include'},
        )
        setup(**setup_args)


    Change <code>packages = [ . . . ],</code> to your list of strings of the name of the folders inside your *include* folder.  By convention, this will be the same name as the package, or <code>'filter_call'</code> . The configures filter_call/include/filter_call as a python module available to the whole workspace.

3.	Save and close the file.

    In order for this folder to be treated as a python module, the <code>\__init__.py</code> file must exist.

4.	Create one in the terminal by typing:

        touch filter_call/include/filter_call/__init__.py

5.	We are almost ready to start developing the client node to call our C++ service. Before we can do that, we need to create a service called ‘FilterCloud.srv’ in the lesson_perception package as outlined in Section 2.0, updating the <code>CMakeLists.txt</code> and the <code>package.xml</code> file respectively.  Copy and paste the following into the file.


        #request
        sensor_msgs/PointCloud2 input_cloud
        string topic
        string pcdfilename
        
        # Removes objects outside a defined grid pattern x,y,z
        byte VOXELGRID=0
        
        # Removes the objects based on volume of space
        byte PASSTHROUGH=1
        
        # Issolate objects located along the largest flat surface (floor)
        byte PLANESEGMENTATION=2
        
        # Determine clusters based on pcd density to identify multiple objects
        byte CLUSTEREXTRACTION=3
        
        # Operation to be performed
        byte operation
        
        ---
        #response
        sensor_msgs/PointCloud2 output_cloud
        bool success

    *__As it stands, this file is actually already provided in the lesson_perception package on github__

# Publishing the Point Cloud


As iterated before, we are creating a ROS C++ node to filter the point cloud when requested by a Python node running a service request for each filtering operation, resulting in a new, aggregated point cloud.  Let’s start with modifying our C++ code to publish in a manner supportive to python. Remember, the C++ code is already done so all you need to do is write your python script and view the results in rviz.

# <big>Implement a Voxel Filter</big>

1.	In *perception_node.cpp*, uncomment the boolean function called <code>filterCallBack</code> (just above <code>main</code>) which performs in the service. This will be the service used by the python client to run subsequent filtering operations.


        bool filterCallback(lesson_perception::FilterCloud::Request& request,
                            lesson_perception::FilterCloud::Response& response)
        {
          pcl::PointCloud<pcl::PointXYZ>::Ptr cloud (new pcl::PointCloud<pcl::PointXYZ>);
          pcl::PointCloud<pcl::PointXYZ>::Ptr filtered_cloud (new pcl::PointCloud<pcl::PointXYZ>);
        
          if (request.pcdfilename.empty())
          {
            pcl::fromROSMsg(request.input_cloud, *cloud);
            ROS_INFO_STREAM("cloud size: " << cloud->size());
          }
          else
          {
            pcl::io::loadPCDFile(request.pcdfilename, *cloud);
          }
        
          if (cloud->empty())
          {
            ROS_ERROR("input cloud empty");
            response.success = false;
            return false;
          }
        
          switch (request.operation)
          {
        
            case lesson_perception::FilterCloud::Request::VOXELGRID :
            {
              filtered_cloud = voxelGrid(cloud, 0.01);
              break;
            }
            default :
            {
              ROS_ERROR("No valid request found");
              return false;
            }
        
           }
        
        /*
         * SETUP RESPONSE
         */
          pcl::toROSMsg(*filtered_cloud, response.output_cloud);
          response.output_cloud.header=request.input_cloud.header;
          response.output_cloud.header.frame_id="kinect_link";
          response.success = true;
          return true;
        }
        
    *__Base perception_node.cpp file needs to be updated to have this be what is commented out. Th current one is too bare. Or they just need to be told to copy paste this__

2. Within <code>main</code>, uncomment this line. Save and build. 

        priv_nh_.param<double>("leaf_size", leaf_size_, 0.0f); 

2. Now that we have the framework for the filtering, open your terminal. Make sure you are in the filter_call directory. Create a *scripts* folder.

        mkdir scripts

3. If Pycharm is still open, save and close.  We need to open Pycharm from the terminal to make sure it is sourced correctly for C++ node to be heard.  To open

    1. <code>cd ~/pycharm-community-2018.1.3/bin</code>

    2. <code>./pycharm.sh</code>
    
    *__the "pycharm.sh" file may not be located in the user's home directory. My fresh install is is "/snap/pycharm-community/64/bin/". I __

    Once open, locate and right click on the folder *scripts* and create a new python file.  Call it *filter_call.py*

4. Copy and paste the following code at the top of *filter_call.py* to import necessary libraries:

        #!/usr/bin/env python
        
        import rospy
        import lesson_perception.srv
        from sensor_msgs.msg import PointCloud2

5. We will create an <code>if</code> statement to run our python node when this file is executed. Initalize as follows:


        if __name__ == '__main__':
            try:
            
            except Exception as e:
                print("Service call failed: %s" % str(e))


6. Include a <code>rospy.spin()</code> in the <code>try</code> block to look like the following:

        if __name__ == '__main__':
            try:
                rospy.spin()
            except Exception as e:
                print("Service call failed: %s" % str(e))


7. Copy and paste the following inside the <code>try</code> block:


        # =======================
        # VOXEL GRID FILTER
        # =======================

        srvp = rospy.ServiceProxy('filter_cloud', lesson_perception.srv.FilterCloud)
        req = lesson_perception.srv.FilterCloudRequest()
        req.pcdfilename = rospy.get_param('~pcdfilename', '')
        req.operation = lesson_perception.srv.FilterCloudRequest.VOXELGRID
        # FROM THE SERVICE, ASSIGN POINTS
        req.input_cloud = PointCloud2()

        # ERROR HANDLING
        if req.pcdfilename == '':
            raise Exception('No file parameter found')

        # PACKAGE THE FILTERED POINTCLOUD2 TO BE PUBLISHED
        res_voxel = srvp(req)
        print('response received')
        if not res_voxel.success:
            raise Exception('Unsuccessful voxel grid filter operation')

        # PUBLISH VOXEL FILTERED POINTCLOUD2
        pub = rospy.Publisher('/perception_voxelGrid', PointCloud2, queue_size=1, latch=True)
        pub.publish(res_voxel.output_cloud)
        print("published: voxel grid filter response")



8. Paste the following lines above the <code>try</code> block (still within the <code>if</code> statement) to initialize the python node and wait for the C++ node's service.

        rospy.init_node('filter_cloud', anonymous=True)
        rospy.wait_for_service('filter_cloud')
        
    *__We need to make the python file executable. <code>chmod +x filter_call/scripts/filter_call.py</code>__

# <big>Viewing Results</big>

1. In your terminal, run

        roscore

2. Source a new terminal and run the C++ filter service node

        rosrun lesson_perception perception_node

3. Source a new terminal and run the python service caller node

        rosrun filter_call filter_call.py _pcdfilename:="/me/ros-industrial/catkin_ws/table.pcd"
        
    *__The issue still lies that the file will not be located there. If they are on the vm, it will be "/home/ros-industrial/table.pcd", and if they are using their own machine, it will likely be "/home/USERNAME/table.pcd", but in general it will be /PATH/TO/HOME/table.pcd__

4. Source a new terminal and run rviz

        rosrun rviz rviz

5. Add a new PointCloud2 in rviz

6. In global options, change the fixed frame to kinect_link, and in the PointCloud 2, select your topic to be '/perception_voxelGrid'

    You may need to uncheck and recheck the PointCloud2.

# Implement Pass-Through Filters

1. In *perception_node.cpp* in the <code>lesson_perception</code> package, within <code>main</code>, uncomment these two lines.


        priv_nh_.param<double>("passThrough_max", passThrough_max_, 1.0f);
        priv_nh_.param<double>("passThrough_min", passThrough_min_, -1.0f);


2. Update the switch to look as shown below:


        switch (request.operation)
        {
        
          case lesson_perception::FilterCloud::Request::VOXELGRID :
          {
            filtered_cloud = voxelGrid(cloud, 0.01);
            break;
          }
        
          case lesson_perception::FilterCloud::Request::PASSTHROUGH :
          {
            filtered_cloud = passThrough(cloud);
            break;
          }
          default :
          {
            ROS_ERROR("No valid request found");
            return false;
          }

        
        }

3. Save and build


    # <big>Edit the Python Code</big>


4. Open the python node and copy paste the following code after the voxel grid, before the <code>rospy.spin()</code>.  Keep care to maintain indents:


        # =======================
        # PASSTHROUGH FILTER
        # =======================

        srvp = rospy.ServiceProxy('filter_cloud', lesson_perception.srv.FilterCloud)
        req = lesson_perception.srv.FilterCloudRequest()
        req.pcdfilename = ''
        req.operation = lesson_perception.srv.FilterCloudRequest.PASSTHROUGH
        # FROM THE SERVICE, ASSIGN POINTS
        req.input_cloud = res_voxel.output_cloud

        # PACKAGE THE FILTERED POINTCLOUD2 TO BE PUBLISHED
        res_pass = srvp(req)
        print('response received')
        if not res_voxel.success:
            raise Exception('Unsuccessful pass through filter operation')

        # PUBLISH PASSTHROUGH FILTERED POINTCLOUD2
        pub = rospy.Publisher('/perception_passThrough', PointCloud2, queue_size=1, latch=True)
        pub.publish(res_pass.output_cloud)
        print("published: pass through filter response")

5. Save and run from the terminal

    Within Rviz, compare PointCloud2 displays based on the /kinect/depth_registered/points (original camera data) and perception_passThrough (latest processing step) topics. Part of the original point cloud has been “clipped” out of the latest processing result.
    
    *__In order for the original point cloud to show, you need to run some commands from the original perception pipeline tutorial. This only publishes the filtered ones. Or the python node would have to be modified to print that as well.__

    When you are satisfied with the pass-through filter results, press Ctrl+C to kill the node. There is no need to close or kill the other terminals/nodes.


# Plane Segmentation

This method is one of the most useful for any application where the object is on a flat surface. In order to isolate the objects on a table, you perform a plane fit to the points, which finds the points which comprise the table, and then subtract those points so that you are left with only points corresponding to the object(s) above the table. This is the most complicated PCL method we will be using and it is actually a combination of two: the RANSAC segmentation model, and the extract indices tool. An in depth example can be found on the <a href="PCL Plane Model Segmentation Tutorial" target="http://pointclouds.org/documentation/tutorials/planar_segmentation.php#planar-segmentation">PCL Plane Model Segmentation Tutorial</a>; otherwise you can copy the below code snippet.


1. In perception_node.cpp, in <code>main</code>, uncomment

        priv_nh_.param<double>("maxIterations", maxIterations_, 200.0f);
        priv_nh_.param<double>("distThreshold", distThreshold_, 0.01f);


2. Update the switch statement in <code>filterCallback</code> to look as shown below:


        switch (request.operation)
        {
        
          case lesson_perception::FilterCloud::Request::VOXELGRID :
          {
            filtered_cloud = voxelGrid(cloud, 0.01);
            break;
          }
        
          case lesson_perception::FilterCloud::Request::PASSTHROUGH :
          {
            filtered_cloud = passThrough(cloud);
            break;
          }
          case lesson_perception::FilterCloud::Request::PLANESEGMENTATION :
          {
            filtered_cloud = planeSegmentation(cloud);
            break;
          }
          default :
          {
            ROS_ERROR("No valid request found");
            return false;
          }
        
        }


3. Save and build

#<big>Edit the Python Code</big>

4. Copy paste the following code in filter_call.py, after the passthrough filter section.  Keep care to maintain indents:

        # =======================
        # PLANE SEGMENTATION
        # =======================

        srvp = rospy.ServiceProxy('filter_cloud', lesson_perception.srv.FilterCloud)
        req = lesson_perception.srv.FilterCloudRequest()
        req.pcdfilename = ''
        req.operation = lesson_perception.srv.FilterCloudRequest.PLANESEGMENTATION
        # FROM THE SERVICE, ASSIGN POINTS
        req.input_cloud = res_pass.output_cloud

        # PACKAGE THE FILTERED POINTCLOUD2 TO BE PUBLISHED
        res_seg = srvp(req)
        print('response received')
        if not res_voxel.success:
            raise Exception('Unsuccessful plane segmentation operation')

        # PUBLISH PLANESEGMENTATION FILTERED POINTCLOUD2
        pub = rospy.Publisher('/perception_planeSegmentation', PointCloud2, queue_size=1, latch=True)
        pub.publish(res_seg.output_cloud)
        print("published: plane segmentation filter response")


5. Save and run from the terminal

    Within Rviz, compare PointCloud2 displays based on the /kinect/depth_registered/points (original camera data) and perception_planeSegmentation (latest processing step) topics. Only points lying above the table plane remain in the latest processing result.
    
    *__Again, something more needs to be done to show the original camera data__

    1. When you are done viewing the results you can go back and change the ”setMaxIterations” and “setDistanceThreshold” parameter values to control how tightly the plane-fit classifies data as inliers/outliers, and view the results again. Try using values of <code>maxIterations=100</code> and <code>distThreshold=0.010</code>

    *__Maybe specify that the parameters are associated with the perception node?__

    2. When you are satisfied with the plane segmentation results, use Ctrl+C to kill the node. There is no need to close or kill the other terminals/nodes.



# Euclidian Cluster Extraction

This method is useful for any application where there are multiple objects. This is also a complicated PCL method. An in depth example can be found on the <a href="PCL Euclidean Cluster Extration Tutorial" target="http://pointclouds.org/documentation/tutorials/cluster_extraction.php#cluster-extraction">PCL Euclidean Cluster Extration Tutorial</a>.


1. In perception_node.cpp <code>main</code> uncomment


        priv_nh_.param<double>("clustTol", clustTol_, 0.01f);
        priv_nh_.param<double>("clustMax", clustMax_, 10000.0);
        priv_nh_.param<double>("clustMin", clustMin_, 300.0f);


2. Update the switch statement in <code>filterCallback</code> to look as shown below:


        switch (request.operation)
        {
        
          case lesson_perception::FilterCloud::Request::VOXELGRID :
          {
            filtered_cloud = voxelGrid(cloud, 0.01);
            break;
          }
        
          case lesson_perception::FilterCloud::Request::PASSTHROUGH :
          {
            filtered_cloud = passThrough(cloud);
            break;
          }
          case lesson_perception::FilterCloud::Request::PLANESEGMENTATION :
          {
            filtered_cloud = planeSegmentation(cloud);
            break;
          }
          case lesson_perception::FilterCloud::Request::CLUSTEREXTRACTION :
          {
            std::vector<pcl::PointCloud<pcl::PointXYZ>::Ptr> temp =clusterExtraction(cloud);
            if (temp.size()>0)
            {
              filtered_cloud = temp[0];
            }
            //filtered_cloud = clusterExtraction(cloud)[0];
            break;
          }
          default :
          {
            ROS_ERROR("No valid request found");
            return false;
          }
        
        }

    *__Should "//filtered_cloud = clusterExtraction(cloud)[0];" be in the code?__

3. Save and build


# <big>Edit the Python Code</big>


4. Copy paste the following code in filter_call.py after the plane segmentation section.  Keep care to maintain indents:

        # =======================
        # CLUSTER EXTRACTION
        # =======================

        srvp = rospy.ServiceProxy('filter_cloud', lesson_perception.srv.FilterCloud)
        req = lesson_perception.srv.FilterCloudRequest()
        req.pcdfilename = ''
        req.operation = lesson_perception.srv.FilterCloudRequest.CLUSTEREXTRACTION
        # FROM THE SERVICE, ASSIGN POINTS
        req.input_cloud = res_seg.output_cloud

        # PACKAGE THE FILTERED POINTCLOUD2 TO BE PUBLISHED
        res_cluster = srvp(req)
        print('response received')
        if not res_voxel.success:
            raise Exception('Unsuccessful cluster extraction operation')

        # PUBLISH CLUSTEREXTRACTION FILTERED POINTCLOUD2
        pub = rospy.Publisher('/perception_clusterExtraction', PointCloud2, queue_size=1, latch=True)
        pub.publish(res_cluster.output_cloud)
        print("published: cluster extraction filter response")


5. Save and run from the terminal

    1. When you are satisfied with the cluster extraction results, use Ctrl+C to kill the node. If you are done experimenting with this tutorial, you can kill the nodes running in the other terminals.


# Future Study

The student is encouraged to convert <a href="Exercise 5.1" target="http://ros-industrial.github.io/industrial_training/_source/session5/Building-a-Perception-Pipeline.html">Exercise 5.1</a> into callable functions and further refine the filtering operations.

*__ By "Exercise 5.1", do you mean the standard 5.1 or this tutorial? Are you referring to the C++ node?__

Furthermore, for simplicity, the python code was repeated for each filtering instance. The student is encouraged to create a function to handle the publishing, including full functionality of the parameter handeling.

*__What exactly do you mean here. It is not clear__